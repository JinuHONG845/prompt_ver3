import streamlit as st
import openai
from anthropic import Anthropic
import google.generativeai as genai
import requests
import json

# API í‚¤ ì„¤ì •
openai.api_key = st.secrets["api_keys"]["OPENAI_API_KEY"]
anthropic = Anthropic(api_key=st.secrets["api_keys"]["ANTHROPIC_API_KEY"])
genai.configure(api_key=st.secrets["api_keys"]["GEMINI_API_KEY"])
PERPLEXITY_API_KEY = st.secrets["api_keys"]["PERPLEXITY_API_KEY"]

def get_perplexity_response(prompt):
    url = "https://api.perplexity.ai/chat/completions"
    headers = {
        "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "mixtral-8x7b-instruct",
        "messages": [{"role": "user", "content": prompt}]
    }
    
    response = requests.post(url, headers=headers, json=data)
    return response.json()["choices"][0]["message"]["content"]

def get_chatgpt_response(prompt):
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content

def get_claude_response(prompt):
    message = anthropic.messages.create(
        model="claude-3-sonnet-20240229",
        max_tokens=1000,
        messages=[{"role": "user", "content": prompt}]
    )
    return message.content[0].text

def get_gemini_response(prompt):
    model = genai.GenerativeModel('gemini-pro')
    response = model.generate_content(prompt)
    return response.text

def main():
    st.title("ğŸ¤– LLM ë¹„êµ ì• í”Œë¦¬ì¼€ì´ì…˜")
    
    # ì‚¬ì´ë“œë°”ì— ëª¨ë¸ ì„ íƒ
    models = st.sidebar.multiselect(
        "ë¹„êµí•  ëª¨ë¸ ì„ íƒ",
        ["Perplexity", "ChatGPT", "Claude", "Gemini"],
        default=["Perplexity", "ChatGPT", "Claude", "Gemini"]
    )
    
    # í”„ë¡¬í”„íŠ¸ ì…ë ¥
    prompt = st.text_area("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=100)
    
    if st.button("ì‘ë‹µ ìƒì„±"):
        if not prompt:
            st.warning("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
            
        # ì„ íƒëœ ëª¨ë¸ë³„ë¡œ ì‘ë‹µ ìƒì„±
        for model in models:
            with st.expander(f"{model} ì‘ë‹µ"):
                with st.spinner(f"{model} ì‘ë‹µ ìƒì„± ì¤‘..."):
                    try:
                        if model == "Perplexity":
                            response = get_perplexity_response(prompt)
                        elif model == "ChatGPT":
                            response = get_chatgpt_response(prompt)
                        elif model == "Claude":
                            response = get_claude_response(prompt)
                        else:  # Gemini
                            response = get_gemini_response(prompt)
                        
                        st.write(response)
                    except Exception as e:
                        st.error(f"{model} ì—ëŸ¬ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main()
